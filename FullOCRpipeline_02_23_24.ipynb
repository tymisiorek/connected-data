{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9391bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7da00bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pdf2image\n",
    "\n",
    "from io import StringIO\n",
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "from openai import OpenAI\n",
    "\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from lcocr import *\n",
    "\n",
    "path2scans = 'Scans/'\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c4958f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "scanConverted = pdf2image.convert_from_path(os.path.join(path2scans, 'CurvedText.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a3620e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Board of Regents (University of California System) continued.:-.-.. 9-0 -,\n",
      "\n",
      "Sherry L. Lansing. i... ee eee eee eb baleen Pe Regent\n",
      "Affiliation: Chief Executive Officer, ‘The: Sherry L Lansing vot\n",
      "Foundation coe\n",
      "2121 Avenue. of the Stars, Suite 2020, Los Angeles, CA 90067 .\n",
      "\n",
      "Tel: (310) 788-0057 ;\n",
      "\n",
      "_ Education: Northwestern BS... 0: - ey ree\n",
      "Monica C. Lozano ........ 0.0. cece een eect e eens .... Regent\n",
      "Affiliation: Publisher and Chief Executive Officer, .La Opinién; cop teste\n",
      "Senior Vice President, Newspapers, ImpreMedia, LLC oo beat\n",
      "700 South Flower Street, 30th Floor, Los Angeles, CA 90017.\n",
      "\n",
      "Tel: (213) 896-2153 ,\n",
      "\n",
      "George M. Marcus... .... 0.6.6 cece eee ee eee ee eee es eee Regent\n",
      "Affiliation: Founder and Chairman, The Marcus. &. Millichap re\n",
      "Company -\n",
      "16830 Ventura Boulevard, Suite. 100, Encino, CA 91436\n",
      "Education: San Francisco State 1965 BA /\n",
      "\n",
      "Hadi Makarechian .:.........:c0lecceelellelvsececeeues ~ Rese\n",
      "Career: Chairman and Chief Executive Officer, Capital Pacific oe\n",
      "Holdings, Inc. (1991-2008) - - ,\n",
      "\n",
      "Jack O’Connell........ 0... cc cece ee cece eee EX Officio ‘Répént\n",
      "Education: Cal State (Fullerton) BA oo,\n",
      "Norman J. Pattiz .........5.05., DEI So. a Regent\n",
      "\n",
      "Affiliation: Chairman, Westwood One ae\n",
      "\n",
      "9540 Washington Boulevard; Culver City, CA 90230\n",
      "\n",
      "Tel: (310) 840- 4201 gs\n",
      "\n",
      "Education: Southeastern Illinois 1998 DFA — 7 oe. Do\n",
      "Harry Powell ............200005 beep eee ees Faculty Representative\n",
      "Bonnie. M. Reiss... 0.0... cece entero eet ee - _.. Regent\n",
      "\n",
      "Affiliation: Operating Advisor, Pegasus Capital Advisors, L. P oe\n",
      "\n",
      "Education: Miami BS; Antioch Law JD\n",
      "\n",
      "Frederick R. Ruiz... 0... cc ee cee eee eet ee eens Regent\n",
      "Affiliation: Chairman, and Chief Executive Officer, Ruiz Foods, ..\n",
      "\n",
      "Inc.\n",
      "\n",
      "“P.O. Box 37, Dinuba, cA 93618 i , Co af\n",
      "Tel: (559) 591-5510: me Po\n",
      "\n",
      "Leslie Tang Schilling . Cece abe ee LOD eee eens . s >Regent\n",
      "Affiliation: Founder and Chairman, Union Square Investment: cs\n",
      "Company :\n",
      "\n",
      "Education: American. School Foundation (Mexico) BS;\n",
      "U Guadalajara (Mexico) MD\"\n",
      "\n",
      "Arnold Schwarzenegger... .’..... President of the Board and Be Officio\n",
      "Affiliation: Governor (R), State or California * Regent\n",
      "State Capitol, Ist Floor, Sacramento, CA 95814 °° cos\n",
      ". Tel: (916) 445-284)\n",
      "\n",
      "-. Education: Wisconsin (Superior) 1980 BA . Le pe\n",
      "\n",
      "D‘Artagnan Scorza...... eee ene tae eeeees - “ wi vies. Student Regent\n",
      "\n",
      "David Shewmake... 00... 00. 00. beeen ee wan ee lle Ex Officio Regent\n",
      "\n",
      "Bruce D. Varner .... 0... cece cee rece e teen eee eeenies ~ Regent\n",
      "“Affiliation: Partner, Varner & Brandt LLP... :\n",
      "3750 University Avenue, Suite 610, Riverside, CA 92501-3323:\n",
      "\n",
      "Tel: (951) 274-7777\n",
      "Education: UC Santa Barbara:’'1958 BA;' Hastings 1962 JD -\n",
      "\n",
      "Paul D. Wachter .........csereeeeeeee ee eee eee ec steve sees Regent\n",
      "\n",
      "Affiliation: President and Chief Executive Officer, Main Street\n",
      "\n",
      "‘Advisors ~. - Bo\n",
      "\n",
      "3110 Main Street, Suite 300, Santa Monica, CA. 90405. Poles\n",
      ">. Tels. (310) 392-7607 ww, oo, a\n",
      "\n",
      "Mark G. Yudof..... eee eee re sete eee ees EX. Officio o Regen\n",
      "\n",
      "University of Central Arkansas\n",
      "\n",
      "ye\n",
      "\n",
      "201 Donaghey Avenue, Conway, AR 72035\n",
      "Tel: (501) 450-5000 Internet: www.uca.cdu\n",
      "\n",
      "Enrollment: Over 12, 000 Faculty: Over 500° Year. Founded: : 1907.\n",
      "\n",
      "beeen\n",
      "of fa\n",
      "\n",
      "Administration He ,\n",
      "President (Interim) Thomas C. Courtway............ . (501), 450- 5286\n",
      "E-mail: courtway@uca.cdu os\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img = np.array(scanConverted[1])\n",
    "\n",
    "point_list, rotated_orig_Image = rotate_image(img)\n",
    "\n",
    "unrotatedImage, firstWhiteUnRotated, lastWhiteUnRotated = straighten_image(point_list, rotated_orig_Image)\n",
    "\n",
    "split_image, rect1, rect2 = column_split(unrotatedImage, firstWhiteUnRotated, lastWhiteUnRotated)\n",
    "\n",
    "#split_image = add_cv2_rect(split_image, rect1, rectangleColor = (255, 100, 0))\n",
    "#split_image = add_cv2_rect(split_image, rect2, rectangleColor = (255, 100, 0))\n",
    "\n",
    "rescale_factor = 2.3\n",
    "binimage = binarize_image(split_image, rescale_factor=rescale_factor)\n",
    "rect1.rescale(rescale_factor=rescale_factor)\n",
    "rect2.rescale(rescale_factor=rescale_factor)\n",
    "\n",
    "table_text = extract_text(binimage, rect=rect1)\n",
    "print(table_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1d1ddc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Administration: continued -\n",
      "\n",
      "Provost and Dean of the Faculty (nterim) :\n",
      "Keith Atkinson ........0 0. 85 cece eee eee eee dae Go”) ASQ-5397\n",
      "E-mail: keitha@uca.edu 7 tte g gg\n",
      "Education: Mississippi BBA, MBA _\n",
      "\n",
      "Executive Vice President Barbara. PR Anderson re oe oes > God) 480-3 “i\n",
      "E-mail: barbaraa@uca:edu’-\" .\n",
      "\n",
      "Senior Vice President Joe Darling.......... bate eeeeee (501) 450-3\\1€\n",
      "\n",
      "Vice President, Administration Jack Gillean. 0 2......0). (501) 459-3)7C:\n",
      "\n",
      "Vice President, Financial Services Paul MeLendon we eee s (501) 450-3005\n",
      "\n",
      "E-mail: paulmc@uca.edu. : Py Tee\n",
      "Vice President, Institutional Advancement. Sey\n",
      "\n",
      "Kelley L. Erstine ..........ce sce e tee cece eee ees (501) 459-33; s\n",
      "E-mail: kerstine@uca.edu\n",
      "Vice President, Student Services Ronnie Williams ... a (501) 450-3416.\n",
      "Associate Vice President, Academic Development °\n",
      "Willie Hardin .......... 0.020 c cece eee eee ee eee oan (501) 450-5805\n",
      "\n",
      "E-mail: willich@uca.edu\n",
      "\n",
      "Associate Vice President, Communications\n",
      "Warwick Sabin .......----.sseeeresenyrreetee - 601) 4 450-367\n",
      "“E-mail: wsabin@uca.edu Se :\n",
      "Education: Arkansas 1998; Oxford (UK) 2000 MA .\n",
      "\n",
      "Associate Vice President, Human‘ Resources aid \" :\n",
      "“Associate General Counsel Rita Fleming...........-. “0l) 450-5053\n",
      "E-mail: rfleming@uca.cdu vee\n",
      "\n",
      "Dean, Academic Outreach and Bxtendéd Programs ~\n",
      "\n",
      "Leonard Seawood...... acc c eee en been see een enes ( 501) 450-38\n",
      "“E-mail: Iseawood@uca.edu ee “Fax: (501) 450-527\n",
      "Dean, Graduate School Elaine MclNiece.,...... o a Lees (S01) 450-312<.\n",
      "E- mail: elainem@uca.cdu ete es\n",
      "Dean; Undergraduate Studies Sally Roden . whee beeen ens ..- (501) 450-507 =\n",
      "E-mail: sallyr@mail.uca.edu’ ne\n",
      "Dean of Students Gary Roberts... .. beeaee ue vee es leas . . (501) 450-341\n",
      "E-mail: garyr@uca.edu' * . wee 7\n",
      "Associate Dean, Student Life Wendy Holbrook . vebeedcee 2,601) 450-3135\n",
      "Director, Admissions and Institutional Researcli, 7\n",
      ". Melissa Goff.............. 00000 eee. Seite. : G01)’ 450- 5371\n",
      "\n",
      "“Bemail: mgoff@uca.edu rs 07 i\n",
      "Education: Oklahoma 1983 BBA 7\n",
      "\n",
      "Director, Alumni Services Jan Newcomer... .... ... tees 600 450-311=\n",
      "E-mail: jann@uca.edu Tee\n",
      "Director, Athletics Brad’ Teague......... Leeeeueeeaee 501) 450- 5337\n",
      "Director, Career Planning and Placement as 7 ;\n",
      "Kathy Clayborn.............00c ene avec ees wes (501) 450-313\n",
      "Director, General Education Conrad Shumaker. Soe eeee “(501) 450-500C:\n",
      "E-mail: shumaker@uca.edu bbe\n",
      "Director, Honors College Rick Scott... 0.00.4. cuee eee (501) 450-3198\n",
      "..E-mail:.ricks@uca.edu - se\n",
      "Director, Internal Audits Pamela Massey... . beens, (501) 450-5002\n",
      "Director, International Programs James. Brosam wees (501) 450-3445\n",
      "Director, Library Art Lichtenstein............ whe etag . (501) 450-520>\n",
      "Director, Sponsored, Programs Charlotte Cone wee etlaeae (5 01)-450-3451\n",
      "E-mail: ccone@uca.edu _. .,. Fax: (501) 450-533\n",
      "Director, Student Accounts Rick McCollum. wee oe we we o ¥ (S01) 450-5016\n",
      "\n",
      "Director, Student Center, Hank Phelps. cece eee eneeaes (501) 450-3235\n",
      "\n",
      "Administrative Services _ ye\n",
      "University of Central Arkansas: Foundation - 7\n",
      "Buffalo Alumni Hall, UCA Box.4986, Conway, AR. 72035-4986\n",
      "Tel: (501) 450-5288 Tel: (800) 981-4426 Fax: (501) 450-5293\"\n",
      "Type of Foundation: University Foundation re\n",
      "\n",
      "Foundation Administrator Kathy, Carroll. ... .... a cee ewes 00 450- 288.\n",
      "‘E-mail: kearroll@uca.edu Co\n",
      "\n",
      "A,\n",
      "\n",
      "wr a ca ; ot\n",
      "oa tat fiueg dy\n",
      "\n",
      "Government Affairs\n",
      "General Counsel and Director, Governmental Relations aa\n",
      "‘Thomas'C. Courtway..... 2... .0.. 0... .see ea 601) 352. 265°\n",
      "E-mail: courtway@uca.edu a\n",
      "Assistant Vice President, University ‘Relations’ et\n",
      "Jeff Pitchford......... nde e eee e eee eeeeee eel . . (00) 450-3170\n",
      "E-mail: jeffp@uca.edu ee ce\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "table_text = extract_text(binimage, rect=rect2)\n",
    "print(table_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cd8ab6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11cff814b8e14474bbe577356d530813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "llama-2-7b-chat.Q4_K_M.gguf:   0%|          | 0.00/4.08G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /Users/hgt6rn/Desktop/models/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  3891.24 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =    10.01 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    70.50 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 1\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '32', 'llama.context_length': '4096', 'llama.attention.head_count': '32', 'llama.rope.dimension_count': '128', 'general.file_type': '15', 'llama.feed_forward_length': '11008', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'general.name': 'LLaMA v2'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#https://github.com/abetlen/llama-cpp-python\n",
    "\n",
    "\n",
    "from llama_cpp import Llama\n",
    "\n",
    "llm = Llama.from_pretrained(\n",
    "    repo_id=\"TheBloke/Llama-2-7B-Chat-GGUF\",\n",
    "    filename=\"llama-2-7b-chat.Q4_K_M.gguf\",\n",
    "    local_dir = '/Users/hgt6rn/Desktop/models',\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56e8a66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 19 key-value pairs and 291 tensors from /Users/hgt6rn/Desktop/models/llama-2-7b-chat.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 4096\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: n_embd_k_gqa     = 4096\n",
      "llm_load_print_meta: n_embd_v_gqa     = 4096\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 4096\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 3.80 GiB (4.84 BPW) \n",
      "llm_load_print_meta: general.name     = LLaMA v2\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size =    0.11 MiB\n",
      "llm_load_tensors: offloading 0 repeating layers to GPU\n",
      "llm_load_tensors: offloaded 0/33 layers to GPU\n",
      "llm_load_tensors:        CPU buffer size =  3891.24 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_kv_cache_init:        CPU KV buffer size =   256.00 MiB\n",
      "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
      "llama_new_context_with_model:        CPU input buffer size   =    10.01 MiB\n",
      "llama_new_context_with_model:        CPU compute buffer size =    70.50 MiB\n",
      "llama_new_context_with_model: graph splits (measure): 1\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | MATMUL_INT8 = 0 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '32', 'llama.context_length': '4096', 'llama.attention.head_count': '32', 'llama.rope.dimension_count': '128', 'general.file_type': '15', 'llama.feed_forward_length': '11008', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000001', 'general.name': 'LLaMA v2'}\n"
     ]
    }
   ],
   "source": [
    "llm = Llama(\n",
    "      model_path=\"/Users/hgt6rn/Desktop/models/llama-2-7b-chat.Q4_K_M.gguf\",\n",
    "      chat_format=\"llama-2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f3f9a757",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   14802.45 ms\n",
      "llama_print_timings:      sample time =       5.57 ms /    72 runs   (    0.08 ms per token, 12919.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2121.22 ms /    62 tokens (   34.21 ms per token,    29.23 tokens per second)\n",
      "llama_print_timings:        eval time =    3699.69 ms /    71 runs   (   52.11 ms per token,    19.19 tokens per second)\n",
      "llama_print_timings:       total time =    5944.70 ms /   133 tokens\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'id': 'chatcmpl-9d892031-bdec-4985-a15a-ee6271fb87b6',\n",
       " 'object': 'chat.completion',\n",
       " 'created': 1708725576,\n",
       " 'model': '/Users/hgt6rn/Desktop/models/llama-2-7b-chat.Q4_K_M.gguf',\n",
       " 'choices': [{'index': 0,\n",
       "   'message': {'role': 'assistant',\n",
       "    'content': 'Administration: continued -\\n\\nProvost and Dean of the Faculty (interim) :\\nKeith Atkinson ................0 0. 85 cece eee eee eee dae Go”) ASQ-5397\\nE-mail: keitha@uca.edu 7 tte'},\n",
       "   'finish_reason': 'length'}],\n",
       " 'usage': {'prompt_tokens': 440, 'completion_tokens': 72, 'total_tokens': 512}}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages=[\n",
    "            # {\"role\": \"system\", \"content\": \"You are cleaning and organizing data from a Python list.\"},\n",
    "            # {\"role\": \"system\", \"content\": \"You will be provided with unstructured data, and your task is to parse it into CSV format.\"},\n",
    "            {\"role\": \"system\", \"content\": \"You are part of a data processing pipeline. Your task is to parse the data into a tabular format, with no additional annotations or explanations, or it will break the process. Remember, you are only returning tabular information.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Extract the important entities mentioned in the text below. First, extract all names of people, then their current job title (generally Trustee, President, Dean, Chair, Provost, etc.) including prefixes (vice, assistant, associate, senior, etc.), any education/degree they've recieved, (Anything following the phrase, \\\"Education:\\\") finally, current affiliation/positions they hold at other companies, and finally, the university that they work for. \"},\n",
    "            {\"role\": \"user\", \"content\": \"Organize the above information into a tab separated table (tsv table) with the following columns: \"},\n",
    "            {\"role\": \"user\", \"content\": \" Current Institution | SubInstitution | Name | Current Title | Education | Other Affiliation \"},\n",
    "            {\"role\": \"user\", \"content\": \"Create a new line for each name that is extracted. If there are multiple elements to put into one column, separate them by commas. If there is no elements to put into a column, put: N/A.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Sometimes the title appears before the name, sometimes it appears after. Make sure to always put the title in the column Current Title. This column is never empty. If the title is Dean, include the school or college in the SubInstitution column.\"},\n",
    "            #{\"role\": \"user\", \"content\": \"If there is a line of text that contains the line, \\\"Education:\\\", you can NEVER leave that information out of the table. It's critical to ensure that the education column is rarely empty, as missing education information will disrupt the pipeline.\"},\n",
    "            #{\"role\": \"user\", \"content\": \"If there is a line of text that contains the line, \\\"Affiliation:\\\", then always put whatever is listed for that person's affiliation in the table under the column Other Affiliation. Double check for lines containing affiliation. This column is not often empty.\"},\n",
    "            #{\"role\": \"user\", \"content\": \"Make sure to look through the entire text and don't leave any information out. Any incorrect or missing information WILL break the pipeline. Please double check that all of the above instructions have been fulfilled.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Here is the organized data in the format you specified:\\\"\\\"\\\" \"},\n",
    "            {\"role\": \"assistant\", \"content\": table_text[:200]},\n",
    "            {\"role\": \"assistant\", \"content\": \"\\\"\\\"\\\" \"}\n",
    "        ]\n",
    "\n",
    "llm.create_chat_completion(messages = messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "548d1c2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Administration: continued -\\n\\nProvost and Dean of the Faculty (nterim) :\\nKeith Atkinson ........0 0. '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table_text[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c4f504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
