{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "from collections import Counter, defaultdict\n",
    "from matplotlib.lines import Line2D\n",
    "from collections import Counter\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_connected_data = \"C:\\\\Users\\\\tykun\\\\OneDrive\\\\Documents\\\\SchoolDocs\\\\VSCodeProjects\\\\connectedData\\\\dataframes\\\\\"\n",
    "path_temp_data = \"C:\\\\Users\\\\tykun\\\\OneDrive\\\\Documents\\\\SchoolDocs\\\\VSCodeProjects\\\\connectedData\\\\temporaryData\\\\\"\n",
    "path_pos_disambig = \"C:\\\\Users\\\\tykun\\\\OneDrive\\\\Documents\\\\SchoolDocs\\\\VSCodeProjects\\\\connectedData\\\\temporaryData\\\\position_disambiguation\\\\\"\n",
    "\n",
    "valid_years = [\"1999\", \"2000\", \"2005\", \"2008\", \"2009\", \"2013\"]\n",
    "year = 2009\n",
    "path_read = f\"{path_pos_disambig}{year}_split_positions.csv\"\n",
    "boards_path = f\"{path_temp_data}{year}_boards_region.csv\"\n",
    "interlocked_nodes_disjoint_path = f\"{path_temp_data}interlocked_nodes_disjoint.csv\"\n",
    "interlocked_edges_disjoint_path = f\"{path_temp_data}interlocked_edges_disjoint.csv\"\n",
    "\n",
    "interlocked_nodes_continuous_path = f\"{path_temp_data}interlocked_nodes_continuous.csv\"\n",
    "interlocked_edges_continuous_path = f\"{path_temp_data}interlocked_edges_continuous.csv\"\n",
    "\n",
    "interlocked_nodes_sample_path = f\"{path_temp_data}interlocked_nodes_sample.csv\"\n",
    "interlocked_edges_sample_path = f\"{path_temp_data}interlocked_edges_sample.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "board_member_dict = defaultdict(set)\n",
    "edges_list = []\n",
    "nodes_dict = defaultdict(lambda: {'Interlock_Count': 0, 'Region': None})\n",
    "\n",
    "# Iterate through each year\n",
    "for year in valid_years:\n",
    "    boards_path = f\"{path_pos_disambig}{year}_boards_region.csv\"\n",
    "    boards_df = pd.read_csv(boards_path)\n",
    "\n",
    "    # Iterate over each board member\n",
    "    for index, row in boards_df.iterrows():\n",
    "        name = row['Name']\n",
    "        institution = row['Institution']\n",
    "        region = row['Region']  # Assuming 'Region' column exists in boards_df\n",
    "\n",
    "        # If this board member has been seen before in a different institution, record an interlock\n",
    "        for previous_institution in board_member_dict[name]:\n",
    "            if previous_institution != institution:\n",
    "                # Record the interlock as an edge\n",
    "                edges_list.append({\n",
    "                    'Source': previous_institution,\n",
    "                    'Target': institution,\n",
    "                    'Type': 'Undirected',\n",
    "                    'Weight': 1  # Each interlock counts as 1 by default\n",
    "                })\n",
    "                # Increment the interlock count for the involved institutions\n",
    "                nodes_dict[previous_institution]['Interlock_Count'] += 1\n",
    "                nodes_dict[institution]['Interlock_Count'] += 1\n",
    "\n",
    "        # Add the current institution to the set of institutions this member is associated with\n",
    "        board_member_dict[name].add(institution)\n",
    "\n",
    "        # Ensure the Region is recorded for each institution\n",
    "        nodes_dict[institution]['Region'] = region\n",
    "\n",
    "# Create a DataFrame for nodes (universities) with their interlock counts and regions\n",
    "nodes_df = pd.DataFrame([(key, value['Interlock_Count'], value['Region']) for key, value in nodes_dict.items()], \n",
    "                        columns=['Id', 'Interlock_Count', 'Region'])\n",
    "nodes_df['Label'] = nodes_df['Id']  # Use the institution name as the label\n",
    "\n",
    "# Ensure correct column order and uniqueness\n",
    "nodes_df = nodes_df[['Id', 'Label', 'Interlock_Count', 'Region']]\n",
    "\n",
    "# Create a DataFrame for edges (interlocks between institutions)\n",
    "edges_df = pd.DataFrame(edges_list)\n",
    "\n",
    "# Ensure correct column order for edges\n",
    "edges_df = edges_df[['Source', 'Target', 'Type', 'Weight']]\n",
    "\n",
    "# Save the DataFrames to CSV files\n",
    "nodes_df.to_csv(interlocked_nodes_disjoint_path, index=False)\n",
    "edges_df.to_csv(interlocked_edges_disjoint_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assortativity Coefficient based on Region: 0.2832630650063732\n"
     ]
    }
   ],
   "source": [
    "G = nx.Graph()\n",
    "\n",
    "for _, row in edges_df.iterrows():\n",
    "    source_region = nodes_dict[row['Source']]['Region']\n",
    "    target_region = nodes_dict[row['Target']]['Region']\n",
    "    \n",
    "    if pd.notna(source_region) and pd.notna(target_region) and source_region != \"\" and target_region != \"\":\n",
    "        G.add_edge(row['Source'], row['Target'], weight=row['Weight'])\n",
    "\n",
    "region_mapping = {k: v['Region'] for k, v in nodes_dict.items() if pd.notna(v['Region']) and v['Region'] != \"\"}\n",
    "nx.set_node_attributes(G, region_mapping, 'Region')\n",
    "\n",
    "def region_similarity(n1, n2):\n",
    "    return G.nodes[n1]['Region'] == G.nodes[n2]['Region']\n",
    "\n",
    "assortativity_coefficient = nx.attribute_assortativity_coefficient(G, 'Region')\n",
    "\n",
    "print(\"Assortativity Coefficient based on Region (SAMPLE ONLY):\", assortativity_coefficient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_list = []\n",
    "nodes_dict = defaultdict(lambda: {'Interlock_Count': 0, 'Region': None})\n",
    "\n",
    "# Iterate through each year\n",
    "for year in valid_years:\n",
    "    boards_path = f\"{path_pos_disambig}{year}_boards_region.csv\"\n",
    "    boards_df = pd.read_csv(boards_path)\n",
    "\n",
    "    # Group by 'Name' to find individuals who served on multiple boards in the same year\n",
    "    grouped = boards_df.groupby('Name')\n",
    "    \n",
    "    for name, group in grouped:\n",
    "        # Get a list of all unique institutions this individual is part of within the year\n",
    "        institutions = group['Institution'].unique().tolist()\n",
    "        regions = group['Region'].unique().tolist()  # Assuming 'Region' exists in boards_df\n",
    "        \n",
    "        # Check if the individual serves on more than one institution within the same year\n",
    "        if len(institutions) > 1:\n",
    "            # Record the interlock between institutions\n",
    "            for i in range(len(institutions)):\n",
    "                for j in range(i + 1, len(institutions)):\n",
    "                    edges_list.append({\n",
    "                        'Source': institutions[i],\n",
    "                        'Target': institutions[j],\n",
    "                        'Type': 'Undirected',\n",
    "                        'Weight': 1  # Each interlock counts as 1\n",
    "                    })\n",
    "                    # Increment the interlock count for the involved institutions\n",
    "                    nodes_dict[institutions[i]]['Interlock_Count'] += 1\n",
    "                    nodes_dict[institutions[j]]['Interlock_Count'] += 1\n",
    "\n",
    "                    # Add the region for each institution if it's available\n",
    "                    if len(regions) > i:\n",
    "                        nodes_dict[institutions[i]]['Region'] = regions[i]\n",
    "                    if len(regions) > j:\n",
    "                        nodes_dict[institutions[j]]['Region'] = regions[j]\n",
    "\n",
    "# Create a DataFrame for nodes (universities) with their interlock counts and regions\n",
    "nodes_df = pd.DataFrame([(key, value['Interlock_Count'], value['Region']) for key, value in nodes_dict.items()], \n",
    "                        columns=['Id', 'Interlock_Count', 'Region'])\n",
    "nodes_df['Label'] = nodes_df['Id']  # Use the institution name as the label\n",
    "\n",
    "# Create a DataFrame for edges (interlocks between institutions)\n",
    "edges_df = pd.DataFrame(edges_list)\n",
    "\n",
    "# Save the DataFrames to CSV files\n",
    "nodes_df.to_csv(interlocked_nodes_continuous_path, index=False)\n",
    "edges_df.to_csv(interlocked_edges_continuous_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Same thing as above cell, but remove non sample universities\n",
    "\n",
    "edges_list = []\n",
    "nodes_dict = defaultdict(lambda: {'Interlock_Count': 0, 'Region': None})\n",
    "\n",
    "# Iterate through each year\n",
    "for year in valid_years:\n",
    "    boards_path = f\"{path_pos_disambig}{year}_boards_region.csv\"\n",
    "    boards_df = pd.read_csv(boards_path)\n",
    "\n",
    "    # Filter out rows where 'Region' is NaN or an empty string\n",
    "    boards_df = boards_df[boards_df['Region'].notna() & (boards_df['Region'] != \"\")]\n",
    "\n",
    "    # Group by 'Name' to find individuals who served on multiple boards in the same year\n",
    "    grouped = boards_df.groupby('Name')\n",
    "    \n",
    "    for name, group in grouped:\n",
    "        # Get a list of all unique institutions this individual is part of within the year\n",
    "        institutions = group['Institution'].unique().tolist()\n",
    "        regions = group['Region'].unique().tolist()  # Assuming 'Region' exists in boards_df\n",
    "        \n",
    "        # Check if the individual serves on more than one institution within the same year\n",
    "        if len(institutions) > 1:\n",
    "            # Record the interlock between institutions\n",
    "            for i in range(len(institutions)):\n",
    "                for j in range(i + 1, len(institutions)):\n",
    "                    edges_list.append({\n",
    "                        'Source': institutions[i],\n",
    "                        'Target': institutions[j],\n",
    "                        'Type': 'Undirected',\n",
    "                        'Weight': 1  # Each interlock counts as 1\n",
    "                    })\n",
    "                    # Increment the interlock count for the involved institutions\n",
    "                    nodes_dict[institutions[i]]['Interlock_Count'] += 1\n",
    "                    nodes_dict[institutions[j]]['Interlock_Count'] += 1\n",
    "\n",
    "                    # Add the region for each institution if it's available\n",
    "                    if len(regions) > i:\n",
    "                        nodes_dict[institutions[i]]['Region'] = regions[i]\n",
    "                    if len(regions) > j:\n",
    "                        nodes_dict[institutions[j]]['Region'] = regions[j]\n",
    "\n",
    "# Create a DataFrame for nodes (universities) with their interlock counts and regions\n",
    "nodes_df = pd.DataFrame([(key, value['Interlock_Count'], value['Region']) for key, value in nodes_dict.items()], \n",
    "                        columns=['Id', 'Interlock_Count', 'Region'])\n",
    "\n",
    "# Filter out rows in nodes_df where 'Region' is None, NaN, or an empty string\n",
    "nodes_df = nodes_df[nodes_df['Region'].notna() & (nodes_df['Region'] != \"\")]\n",
    "\n",
    "nodes_df['Label'] = nodes_df['Id']  # Use the institution name as the label\n",
    "\n",
    "# Create a DataFrame for edges (interlocks between institutions)\n",
    "edges_df = pd.DataFrame(edges_list)\n",
    "\n",
    "\n",
    "# Save the DataFrames to CSV files\n",
    "nodes_df.to_csv(interlocked_nodes_sample_path, index=False)\n",
    "edges_df.to_csv(interlocked_edges_sample_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projectEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
